[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NYC 311 Service Requests Analysis",
    "section": "",
    "text": "1 Introduction\nNew York City is a bustling metropolis with a diverse range of services and systems that keep the city running smoothly. However, with such complexity, residents may inevitably encounter issues that require government intervention. Data pertaining to the time, location, and content of thousands of 311 calls in New York City is recorded every day. By studying trends in this data, government agencies can respond more effectively to non-emergency requests and issues raised by the populations they serve",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  1. Opening Remarks and Motivation",
    "section": "",
    "text": "2.1 2. Data\nNew York City’s 311 system is how, residents let the city know about issues in their communities, such as noise, heating problems, trash, and illegal parking etc. Each entry in the 311 data represents a moment when someone was concerned enough to reach out to the city for assistance.\nIn this project, we analyze two years of NYC 311 complaint data to answer three main questions:\nThese questions guide the structure of the analysis and the choice of visualizations throughout the report.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1. Opening Remarks and Motivation</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(memoise)\n\n\n\n\nCode\n# library(RSocrata)\n# library(dplyr)\n\n# options(timeout = 600)\n\n# base_url &lt;- \"https://data.cityofnewyork.us/resource/erm2-nwe9.json\"\n\n# get_month_data &lt;- function(year, month) {\n#   start &lt;- sprintf(\"%d-%02d-01T00:00:00\", year, month)\n#   # end = first day of next month\n#   if (month == 12) {\n#     end &lt;- sprintf(\"%d-01-01T00:00:00\", year + 1)\n#   } else {\n#     end &lt;- sprintf(\"%d-%02d-01T00:00:00\", year, month + 1)\n#   }\n\n#   url &lt;- sprintf(\n#     \"%s?$where=created_date &gt;= '%s' AND created_date &lt; '%s'\",\n#     base_url, start, end\n#   )\n#   message(\"Fetching: \", start, \" to \", end)\n#   read.socrata(url)\n# }\n\n# # Example: all months of 2023\n# months &lt;- 1:12\n# list_2023 &lt;- lapply(months, function(m) get_month_data(2023, m))\n# data_2023 &lt;- bind_rows(list_2023)\n# list_2024 &lt;- lapply(months, function(m) get_month_data(2024, m))\n# data_2024 &lt;- bind_rows(list_2024)\n# combined &lt;- rbind(data_2023,data_2024)\n# saveRDS(combined, \"nyc_311_data.rds\")\n\n\n\n\nCode\ncombined=combined &lt;- readRDS(\"nyc_311_data.rds\")\n#combined=combined &lt;- readRDS(\"nyc_311_data.rds\")\n\n\n\n\nCode\nmissing_values_summary &lt;- colSums(is.na(combined))\nmissing_columns &lt;- missing_values_summary[missing_values_summary &gt; 0]\nmissing_table &lt;- data.frame(\n  Column = names(missing_columns),\n  MissingCount = as.numeric(missing_columns)\n)\nsorted_table &lt;- missing_table |&gt;\narrange(desc(MissingCount))\nprint(sorted_table)\n\n\n                           Column MissingCount\n1            taxi_company_borough      6679852\n2                       road_ramp      6668175\n3        bridge_highway_direction      6660223\n4                        due_date      6651779\n5             bridge_highway_name      6639447\n6          bridge_highway_segment      6639437\n7           taxi_pick_up_location      6611318\n8                    vehicle_type      6504338\n9                   facility_type      6199357\n10                       landmark      2652950\n11          intersection_street_1      2180001\n12          intersection_street_2      2176719\n13                 cross_street_1      1903203\n14                 cross_street_2      1902070\n15                  location_type       800974\n16                            bbl       752073\n17                           city       325436\n18                    street_name       244008\n19               incident_address       243812\n20                    closed_date       133656\n21                       latitude       102706\n22                      longitude       102706\n23              location.latitude       102706\n24             location.longitude       102706\n25         location.human_address       102706\n26       x_coordinate_state_plane       102597\n27       y_coordinate_state_plane       101804\n28         resolution_description        93259\n29                     descriptor        78842\n30                   incident_zip        72906\n31 resolution_action_updated_date        37625\n32                   address_type        30391\n33                   created_date            1\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n# 1) Compute missingness per column\nmiss_by_col_all &lt;- combined |&gt;\n  summarise(across(everything(), \\(x) sum(is.na(x)))) |&gt;\n  pivot_longer(everything(), names_to = \"column\", values_to = \"missing_n\") |&gt;\n  mutate(\n    total_n      = nrow(combined),\n    missing_rate = missing_n / total_n\n  ) |&gt;\n  arrange(desc(missing_n))\n\n# 2) Top 25 columns by missing rate, add index label\ntop_missing_rate &lt;- miss_by_col_all |&gt;\n  slice_max(missing_rate, n = 25) |&gt;\n  arrange(desc(missing_rate)) |&gt;\n  mutate(\n    rank_label = paste0(row_number(), \". \", column),\n    rank_label = factor(rank_label, levels = rev(rank_label))  # for coord_flip\n  )\n\n# 3) Nice bar plot\np_missing &lt;- ggplot(top_missing_rate,\n                    aes(x = rank_label, y = missing_rate, fill = missing_rate)) +\n  geom_col(width = 0.8) +\n  coord_flip() +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_viridis_c(\n    option = \"C\",\n    direction = -1,\n    name = \"Missing rate\"\n  ) +\n  labs(\n    title = \"Top Columns by Missingness Rate\",\n    subtitle = \"Showing the 25 columns with the highest proportion of missing values\",\n    x = NULL,\n    y = \"Missingness rate\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.y  = element_text(size = 9),\n    axis.text.x  = element_text(size = 10),\n    plot.title   = element_text(face = \"bold\", size = 16),\n    plot.subtitle = element_text(size = 11),\n    legend.position = \"right\"\n  )\n\np_missing\n\n\n\n\n\n\n\n\n\nCode\n# 4) Threshold + list of columns to drop (same logic as before)\nmissing_threshold &lt;- 0.60\n\ncols_to_drop_by_missing &lt;- miss_by_col_all |&gt;\n  filter(missing_rate &gt; missing_threshold) |&gt;\n  pull(column)\n\n\nThe above horizontal bar graph gives a relative view of missing values in all the columns of the dataset. Missing values can, of course, complicate the analysis; however, in our case, the columns with a high number of missing values are not critical to our primary objectives. The data in these columns—such as taxi_company_borough, road_ramp,bridge_highway_direction, bridge_highway_name bridge_highway_segment,taxi_pick_up_location,vehicle_type,facility_type as supporting information rather than core data required for analysis.\nFor example, columns like bridge_highway_direction only provides metadata about the bridge highway, which is not directly related to analyzing 311 trends . Thus, we can safely drop these columns without significantly impacting our analysis.\n\n\nCode\nset.seed(42)\nsampled_data &lt;- combined[sample(1:nrow(combined), 5000), ]\n\nmissing_long &lt;- as.data.frame(is.na(sampled_data)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"Column\", values_to = \"IsMissing\")\n\nmissing_long &lt;- cbind(RowIndex = rep(1:nrow(sampled_data), times = ncol(sampled_data)), missing_long)\n\n# Plotting heatmap of missing data\nggplot(missing_long, aes(x = Column, y = RowIndex, fill = IsMissing)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"FALSE\" = \"white\", \"TRUE\" = \"red\"), name = \"Missing\") +\n  labs(title = \"Heatmap of Missing Data (Sampled Rows)\",\n       x = \"Columns\",\n       y = \"Row Index\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThe above missing value heatmap shows that missing data is concentrated only in certain columns. The rest of the columns have little to no missing data. This helps us streamline the data cleaning process.\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\nvalid_boros &lt;- c(\"MANHATTAN\", \"BROOKLYN\", \"QUEENS\", \"BRONX\", \"STATEN ISLAND\")\n\ndf_clean_final &lt;- combined |&gt;\n  filter(borough %in% valid_boros)\n\n# Borough counts on cleaned data\nborough_counts &lt;- df_clean_final |&gt;\n  count(borough, name = \"n\") |&gt;\n  mutate(\n    share = n / sum(n),\n    # nice index label\n    boro_label = paste0(row_number(), \". \", borough),\n    # text shown on the bar: comma count + %\n    label_text = paste0(comma(n), \" (\", percent(share, accuracy = 0.1), \")\")\n  ) |&gt;\n  arrange(desc(n)) |&gt;\n  mutate(\n    boro_label = factor(boro_label, levels = rev(boro_label))\n  )\n\nggplot(borough_counts,\n       aes(x = boro_label, y = n, fill = share)) +\n  geom_col(width = 0.7) +\n  geom_text(\n    aes(label = label_text),\n    hjust = -0.05, size = 3.5\n  ) +\n  coord_flip(clip = \"off\") +\n  scale_y_continuous(\n    labels = scales::comma,                     # &lt;-- commas\n    expand = expansion(mult = c(0, 0.30))       # extra room for labels\n  ) +\n  scale_fill_viridis_c(\n    option = \"C\",\n    direction = -1,\n    labels = scales::percent_format(accuracy = 1),\n    name = \"Share of\\ncomplaints\"\n  ) +\n  labs(\n    title = \"Borough Distribution of 311 Complaints\",\n    subtitle = \"Indexed by frequency; labels show count (comma separated) and percent of total\",\n    x = NULL,\n    y = \"Number of complaints\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.y  = element_text(size = 10),\n    axis.text.x  = element_text(size = 10),\n    plot.title   = element_text(face = \"bold\", size = 16),\n    plot.subtitle = element_text(size = 11),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\n\n\n2.2.1 Data Cleaning\nBased on our results above we have decided to remove following columns from our data-set as they are either not useful to us or have a lot of missing values.\nThe columns that we are dropping: taxi_company_borough, road_ramp,bridge_highway_direction, bridge_highway_name, bridge_highway_segment,taxi_pick_up_location,vehicle_type,facility_type, due to high missing values and low relevance to our analysis.\n\n\nCode\n#label\ndf_clean_final &lt;- df_clean_final |&gt;\n  dplyr::select(\n    unique_key, created_date, closed_date, resolution_action_updated_date,\n    agency, agency_name, complaint_type, descriptor, status,\n    borough, city, incident_zip, incident_address,\n    latitude, longitude, location_type,\n    open_data_channel_type,\n    resolution_description\n  )\n#saveRDS(df_clean_final, \"df_clean_final.rds\")\n\n\n\n\nCode\ncombined0 &lt;- combined |&gt;\n  mutate(\n    across(where(is.character), \\(x) str_squish(x)),\n    across(where(is.character), \\(x) na_if(x, \"\"))\n  )\n\nmiss_by_col_all &lt;- combined0 |&gt;\n  summarise(across(everything(), \\(x) sum(is.na(x)))) |&gt;\n  pivot_longer(everything(), names_to = \"column\", values_to = \"missing_n\") |&gt;\n  mutate(total_n = nrow(combined0),\n         missing_rate = missing_n / total_n) |&gt;\n  arrange(desc(missing_n))\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(lubridate)\n\ndf0 &lt;- df_clean_final |&gt;\n  mutate(\n    across(where(is.character), \\(x) str_squish(x)),\n    across(where(is.character), \\(x) na_if(x, \"\")),\n    across(where(is.character), \\(x) na_if(x, \"NA\")),\n    across(where(is.character), \\(x) na_if(x, \"N/A\"))\n  )\n\n\n\n\nCode\nlibrary(redav)\ncritical_cols &lt;- c(\"location_type\", \"complaint_type\", \"borough\")\nplot_missing(df0[critical_cols])\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n# 1. Compute geolocation validity\ngeo_check &lt;- df0 |&gt;\n  transmute(\n    latitude = suppressWarnings(as.numeric(latitude)),\n    longitude = suppressWarnings(as.numeric(longitude)),\n    geo_ok = !is.na(latitude) & !is.na(longitude) &\n      between(latitude, 40, 41.2) &\n      between(longitude, -74.5, -73.2)\n  )\n\n# 2. Prepare summary for % view\ngeo_summary &lt;- geo_check |&gt;\n  count(geo_ok) |&gt;\n  mutate(\n    label = ifelse(geo_ok, \"Valid NYC Coordinates\", \"Invalid / Missing Coordinates\"),\n    pct = n / sum(n)\n  )\n\n# 3. Plot\nggplot(geo_summary, aes(x = label, y = pct, fill = label)) +\n  geom_col(width = 0.6, alpha = 0.85) +\n  geom_text(aes(label = percent(pct, accuracy = 0.1)),\n            vjust = -0.5, size = 5) +\n  scale_y_continuous(labels = percent_format(accuracy = 1),\n                     expand = expansion(mult = c(0, 0.1))) +\n  scale_fill_manual(values = c(\"#1b9e77\", \"#d95f02\")) +\n  labs(\n    title = \"Geolocation Validity of 311 Records\",\n    subtitle = \"Latitude–longitude checked against the NYC bounding box\",\n    x = NULL,\n    y = \"% of Records\",\n    fill = NULL\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ndf_zip &lt;- df_clean_final |&gt;\n  mutate(\n    zip_num = suppressWarnings(as.numeric(incident_zip)),\n    zip_category = case_when(\n      is.na(zip_num) ~ \"Missing ZIP\",\n      zip_num &gt;= 10000 & zip_num &lt;= 11697 ~ \"Valid NYC ZIP\",\n      TRUE ~ \"Invalid ZIP\"\n    )\n  ) |&gt;\n  count(zip_category) |&gt;\n  mutate(\n    percent = n / sum(n),\n    label = paste0(comma(n), \" (\", percent_format(accuracy = 0.1)(percent), \")\")\n  )\n\nggplot(df_zip, aes(x = reorder(zip_category, -n), y = n, fill = zip_category)) +\n  geom_col(width = 0.6) +\n  \n  # FIX: always place labels *just above* bars safely\n  geom_text(\n    aes(label = label),\n    vjust = -0.8,   # pull upward slightly\n    size = 5,\n    fontface = \"bold\"\n  ) +\n  \n  scale_fill_manual(values = c(\n    \"Valid NYC ZIP\" = \"#1b9e77\",\n    \"Invalid ZIP\"   = \"#d95f02\",\n    \"Missing ZIP\"   = \"#7570b3\"\n  )) +\n  \n  # FIX: expand limits so labels never get clipped or flipped\n  scale_y_continuous(\n    labels = comma,\n    expand = expansion(mult = c(0, 0.15))  # extra 15% space above\n  ) +\n  \n  labs(\n    title = \"ZIP Code Quality Summary\",\n    subtitle = \"Distribution of valid, invalid, and missing ZIP codes\",\n    x = NULL,\n    y = \"Number of Records\"\n  ) +\n  \n  theme_minimal(base_size = 15) +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 18),\n    plot.subtitle = element_text(size = 13)\n  )\n\n\n\n\n\n\n\n\n\nCode\ndf_clean &lt;- df_clean_final %&gt;%\n  mutate(\n    zip_num = suppressWarnings(as.numeric(incident_zip))\n  ) %&gt;%\n  filter(\n    !is.na(zip_num),\n    zip_num &gt;= 10000,\n    zip_num &lt;= 11697\n  ) %&gt;%\n  select(-zip_num)\n\n\n\n\nCode\nsaveRDS(df_clean_final, \"df_clean_final.rds\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "3.1 Which complaint types are most common in NYC?\nThere were a unique total of 300 complaint types reported in the dataset. The complaint were bucketed into the following categories for better analysis: Noise Related, Heat/Water/Gas Issues, Buildings and Housing, Sanitation and Waste, Street and Traffic Conditions, Public Safety / Crime / Quality of Life, Vehicle and Parking, Utilities and Power, Pests and Animals, Others / Miscellaneous.\nCode\ndf_clean_final &lt;- readRDS(\"df_clean_final.rds\")\ncomplaint_category_mapping &lt;- list(\n  \"Noise Related\" = c(\n    \"Noise - Residential\", \"Noise - Street/Sidewalk\", \"Noise - Commercial\",\n    \"Noise\", \"Noise - Vehicle\", \"Noise - Helicopter\", \"Noise - Park\",\n    \"Noise - House of Worship\"\n  ),\n  \n  \"Heat/Water/Gas Issues\" = c(\n    \"HEAT/HOT WATER\", \"Water System\", \"WATER LEAK\", \"PLUMBING\",\n    \"Water Leak\", \"Drinking Water\", \"Water Quality\", \"Water Maintenance\",\n    \"Water Drainage\", \"Drinking Water General\", \"Drinking Water Tank\",\n    \"Drinking Water Conservation\", \"Bottled Water\", \"DEP Sidewalk Condition\",\n    \"Non-Residential Heat\", \"Heat/Hot Water\"\n  ),\n  \n  \"Buildings and Housing\" = c(\n    \"PAINT/PLASTER\", \"DOOR/WINDOW\", \"FLOORING/STAIRS\", \"APPLIANCE\",\n    \"Elevator\", \"Lead\", \"SAFETY\", \"Indoor Air Quality\", \"Plumbing\",\n    \"Boilers\", \"Electrical\", \"ELEVATOR\", \"Asbestos\", \"Paint/Plaster\",\n    \"Door/Window\", \"OUTSIDE BUILDING\", \"Wood Pile\", \"Mold\",\n    \"Flooring/Stairs\", \"Appliance\", \"Scaffold Safety\", \"Electric\",\n    \"Unstable Building\", \"Window Guard\", \"Cooling Tower\", \"Peeling Paint\",\n    \"Facade Insp Safety Pgm\", \"Outside Building\"\n  ),\n  \n  \"Sanitation and Waste\" = c(\n    \"UNSANITARY CONDITION\", \"Dirty Condition\", \"Missed Collection\",\n    \"Residential Disposal Complaint\", \"Litter Basket Request\",\n    \"Commercial Disposal Complaint\", \"Litter Basket Complaint\",\n    \"Sanitation Worker or Vehicle Complaint\", \"Dumpster Complaint\",\n    \"Industrial Waste\", \"Seasonal Collection\", \"Institution Disposal Complaint\",\n    \"Transfer Station Complaint\", \"DSNY Internal\"\n  ),\n  \n  \"Street and Traffic Conditions\" = c(\n    \"Street Condition\", \"Traffic Signal Condition\", \"Street Light Condition\",\n    \"Sidewalk Condition\", \"Curb Condition\", \"Street Sign - Damaged\",\n    \"Street Sign - Missing\", \"Street Sign - Dangling\", \"Highway Condition\",\n    \"Highway Sign - Damaged\", \"Highway Sign - Missing\", \"Highway Sign - Dangling\",\n    \"Bridge Condition\", \"Tunnel Condition\", \"DEP Highway Condition\",\n    \"DEP Street Condition\"\n  ),\n  \n  \"Public Safety / Crime / Quality of Life\" = c(\n    \"Homeless Person Assistance\", \"Encampment\", \"Non-Emergency Police Matter\",\n    \"Drug Activity\", \"Graffiti\", \"Illegal Fireworks\", \"Panhandling\",\n    \"Animal-Abuse\", \"Violation of Park Rules\", \"Illegal Posting\",\n    \"Hazardous Materials\", \"Smoking\", \"Unleashed Dog\", \"Urinating in Public\",\n    \"Disorderly Youth\", \"Squeegee\", \"Quality of Life\", \"Face Covering Violation\"\n  ),\n  \n  \"Vehicle and Parking\" = c(\n    \"Illegal Parking\", \"Blocked Driveway\", \"Abandoned Vehicle\",\n    \"Derelict Vehicles\", \"Broken Parking Meter\", \"Municipal Parking Facility\"\n  ),\n  \n  \"Utilities and Power\" = c(\n    \"ELECTRIC\", \"Sewer\", \"Root/Sewer/Sidewalk Condition\", \"Radioactive Material\",\n    \"X-Ray Machine/Equipment\", \"Oil or Gas Spill\"\n  ),\n  \n  \"Pests and Animals\" = c(\n    \"Rodent\", \"Animal in a Park\", \"Unsanitary Pigeon Condition\",\n    \"Harboring Bees/Wasps\", \"Illegal Animal Kept as Pet\", \"Mosquitoes\",\n    \"Pet Shop\", \"Poison Ivy\", \"Illegal Animal Sold\", \"Unsanitary Animal Facility\",\n    \"Animal Facility - No Permit\", \"Unlicensed Dog\", \"Unsanitary Animal Pvt Property\"\n  ),\n  \n  \"Others / Miscellaneous\" = c(\n    \"General Construction/Plumbing\", \"Illegal Dumping\", \"GENERAL\",\n    \"Damaged Tree\", \"Maintenance or Facility\", \"New Tree Request\",\n    \"For Hire Vehicle Complaint\", \"Overgrown Tree/Branches\", \"Consumer Complaint\",\n    \"Vendor Enforcement\", \"Building/Use\", \"Obstruction\", \"Air Quality\",\n    \"Dead/Dying Tree\", \"Dead Animal\", \"Street Sweeping Complaint\",\n    \"Taxi Complaint\", \"Lost Property\", \"Outdoor Dining\",\n    \"Real Time Enforcement\", \"Mobile Food Vendor\", \"Bike/Roller/Skate\",\n    \"Chronic\", \"Special Projects Inspection Team (SPIT)\", \"Illegal Tree Damage\",\n    \"Electronics Waste Appointment\", \"Emergency Response Team (ERT)\",\n    \"Food Poisoning\", \"Smoking or Vaping\", \"Day Care\", \"Standing Water\",\n    \"Investigations and Discipline (IAD)\", \"Remaining Taxi Report\",\n    \"E-Scooter\", \"BEST/Site Safety\", \"Indoor Sewage\", \"For Hire Vehicle Report\",\n    \"Uprooted Stump\", \"Green Taxi Complaint\", \"Ferry Inquiry\", \"Ferry Complaint\",\n    \"Beach/Pool/Sauna Complaint\", \"Tattooing\", \"Plant\", \"Bus Stop Shelter Placement\",\n    \"LinkNYC\", \"Bus Stop Shelter Complaint\", \"Posting Advertisement\",\n    \"Taxi Compliment\", \"AHV Inspection Unit\", \"Adopt-A-Basket\",\n    \"Cranes and Derricks\", \"Recycling Basket Complaint\", \"Found Property\",\n    \"Incorrect Data\", \"Bike Rack\", \"Special Natural Area District (SNAD)\",\n    \"Public Toilet\", \"Dept of Investigations\", \"Lifeguard\", \"Special Operations\",\n    \"Dispatched Taxi Complaint\", \"Boiler\", \"Bench\", \"Building Condition\",\n    \"Taxi Licensee Complaint\", \"Retailer Complaint\", \"Calorie Labeling\",\n    \"ZTESTINT\", \"Public Payphone Complaint\", \"FHV Licensee Complaint\",\n    \"Wayfinding SNW\", \"Leaning\", \"Bar\", \"Building Marshal's Office\",\n    \"Building Marshals office\", \"DOB Posted Notice or Order\",\n    \"Construction Safety Enforcement\", \"Tanning\", \"Executive Inspections\",\n    \"Internal\", \"Code\", \"Private School\", \"Vaccine Mandate Non-Compliance\",\n    \"Dispatched Taxi Compliment\", \"SRDE\", \"Stalled Sites\",\n    \"Sustainability Enforcement\", \"Trans Fat\", \"Food Establishment\",\n    \"Sewer Maintenance\", \"Bike Rack Condition\", \"Construction Lead Dust\"\n  )\n)\n\n# Create a long-format data frame\ncomplaint_mapping_df &lt;- data.frame(\n  complaint_type = unlist(complaint_category_mapping),\n  category = rep(names(complaint_category_mapping), \n                 sapply(complaint_category_mapping, length)),\n  stringsAsFactors = FALSE\n)\nrownames(complaint_mapping_df) &lt;- NULL\nmap_complaint_to_category &lt;- function(complaint_type) {\n  for (category in names(complaint_category_mapping)) {\n    if (complaint_type %in% complaint_category_mapping[[category]]) {\n      return(category)\n    }\n  }\n  return(\"Others / Miscellaneous\")\n}\n\n# Apply the mapping to create complaint_bucket column\ndf_clean_final &lt;- df_clean_final |&gt;\n  mutate(complaint_bucket = sapply(complaint_type, map_complaint_to_category))\n\ncomplaint_bucket_counts &lt;- df_clean_final |&gt;\n  count(complaint_bucket, sort = TRUE)\n\ncomplaint_bucket_borough &lt;- df_clean_final |&gt;\n  group_by(borough, complaint_bucket) |&gt;\n  summarise(count = n(), .groups = \"drop\") |&gt;\n  group_by(borough) |&gt;\n  mutate(\n    total_borough = sum(count),\n    proportion = count / total_borough * 100\n  ) |&gt;\n  ungroup()\n::: {.cell}\n::: {.cell-output-display}  ::: :::",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#which-complaint-types-are-most-common-in-nyc",
    "href": "results.html#which-complaint-types-are-most-common-in-nyc",
    "title": "3  Results",
    "section": "",
    "text": "Code\nggplot(\ncomplaint_bucket_borough,\naes(\n  x = proportion,\n  y = complaint_bucket,\n  fill = borough\n)\n) +\ngeom_col() +\nfacet_wrap(~ borough, scales = \"free_x\") +\nscale_x_continuous(labels = function(x) paste0(x / 1000, \"k\")) +\ntheme_minimal() +\ntheme(\n  legend.position = \"none\",\n  strip.text = element_text(face = \"bold\", size = 11),\n  axis.text.x = element_text(size = 7),\n  axis.text.y = element_text(size = 8)\n) +\nscale_fill_brewer(palette = \"Set2\") +\nlabs(\n  title = \"Complaint Categories by Borough\",\n  subtitle = \"Counts of complaints across categories\",\n  x = \"Count\",\n  y = \"Complaint Category\"\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "data.html#data",
    "href": "data.html#data",
    "title": "2  1. Opening Remarks and Motivation",
    "section": "",
    "text": "2.1.1 2.1 Data Source and Scope\nThe raw data come from the NYC Open Data 311 service request API. To avoid time-outs and memory issues, we chose to download the data month-by-month, combined, and then saved as an .rds file for efficient reuse. In total, the working dataset contains around 6M over a two-year window, from early 2023 through late 2024.\nEach row corresponds to a single 311 complaint and includes the following groups of variables:\n\n2.1.1.1 Timestamps\n\ncreated_date: when the complaint was submitted\n\nclosed_date: when the complaint was closed (if ever)\n\nresolution_action_updated_date: when a resolution action was logged\n\n\n\n2.1.1.2 Categorical Descriptors\n\nagency, agency_name\n\ncomplaint_type and a higher-level complaint_bucket (custom grouping)\n\ndescriptor (more detailed description of the issue)\n\nstatus (e.g., \"Closed\", \"Assigned\", \"In Progress\")\n\n\n\n2.1.1.3 Location Information\n\nborough, incident_zip, incident_address\n\nlocation_type (e.g., \"RESIDENTIAL BUILDING\", \"Street/Sidewalk\")\n\nlatitude, longitude\n\n\n\n2.1.1.4 Channel and Resolution\n\nopen_data_channel_type (e.g., ONLINE, PHONE, MOBILE, OTHER)\n\nresolution_description and resolution_action fields\n\nThroughout the project, we created a cleaned version of the data stored in df_clean_final, which preserves key variables while dropping or recoding unusable columns.\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(memoise)\n\n\n\n\nCode\n# library(RSocrata)\n# library(dplyr)\n\n# options(timeout = 600)\n\n# base_url &lt;- \"https://data.cityofnewyork.us/resource/erm2-nwe9.json\"\n\n# get_month_data &lt;- function(year, month) {\n#   start &lt;- sprintf(\"%d-%02d-01T00:00:00\", year, month)\n#   # end = first day of next month\n#   if (month == 12) {\n#     end &lt;- sprintf(\"%d-01-01T00:00:00\", year + 1)\n#   } else {\n#     end &lt;- sprintf(\"%d-%02d-01T00:00:00\", year, month + 1)\n#   }\n\n#   url &lt;- sprintf(\n#     \"%s?$where=created_date &gt;= '%s' AND created_date &lt; '%s'\",\n#     base_url, start, end\n#   )\n#   message(\"Fetching: \", start, \" to \", end)\n#   read.socrata(url)\n# }\n\n# # Example: all months of 2023\n# months &lt;- 1:12\n# list_2023 &lt;- lapply(months, function(m) get_month_data(2023, m))\n# data_2023 &lt;- bind_rows(list_2023)\n# list_2024 &lt;- lapply(months, function(m) get_month_data(2024, m))\n# data_2024 &lt;- bind_rows(list_2024)\n# combined &lt;- rbind(data_2023,data_2024)\n# saveRDS(combined, \"nyc_311_data.rds\")\n\n\n\n\nCode\ncombined=combined &lt;- readRDS(\"nyc_311_data.rds\")\n#combined=combined &lt;- readRDS(\"nyc_311_data.rds\")\n\n\n\n\n\n2.1.2 2.2 Data Quality: Missingness Across Columns\nBefore doing any substantive analysis, we examined the completeness of the raw 311 dataset. The goal of this step was to understand which variables are reliable, which ones are mostly empty, and where cleaning or dropping variables is justified.\n\n\nCode\nmissing_values_summary &lt;- colSums(is.na(combined))\nmissing_columns &lt;- missing_values_summary[missing_values_summary &gt; 0]\nmissing_table &lt;- data.frame(\n  Column = names(missing_columns),\n  MissingCount = as.numeric(missing_columns)\n)\nsorted_table &lt;- missing_table |&gt;\narrange(desc(MissingCount))\nprint(sorted_table)\n\n\n                           Column MissingCount\n1            taxi_company_borough      6679852\n2                       road_ramp      6668175\n3        bridge_highway_direction      6660223\n4                        due_date      6651779\n5             bridge_highway_name      6639447\n6          bridge_highway_segment      6639437\n7           taxi_pick_up_location      6611318\n8                    vehicle_type      6504338\n9                   facility_type      6199357\n10                       landmark      2652950\n11          intersection_street_1      2180001\n12          intersection_street_2      2176719\n13                 cross_street_1      1903203\n14                 cross_street_2      1902070\n15                  location_type       800974\n16                            bbl       752073\n17                           city       325436\n18                    street_name       244008\n19               incident_address       243812\n20                    closed_date       133656\n21                       latitude       102706\n22                      longitude       102706\n23              location.latitude       102706\n24             location.longitude       102706\n25         location.human_address       102706\n26       x_coordinate_state_plane       102597\n27       y_coordinate_state_plane       101804\n28         resolution_description        93259\n29                     descriptor        78842\n30                   incident_zip        72906\n31 resolution_action_updated_date        37625\n32                   address_type        30391\n33                   created_date            1\n\n\n\n2.1.2.1 2.2.1 Top Columns by Missingness Rate\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n# 1) Compute missingness per column\nmiss_by_col_all &lt;- combined |&gt;\n  summarise(across(everything(), \\(x) sum(is.na(x)))) |&gt;\n  pivot_longer(everything(), names_to = \"column\", values_to = \"missing_n\") |&gt;\n  mutate(\n    total_n      = nrow(combined),\n    missing_rate = missing_n / total_n\n  ) |&gt;\n  arrange(desc(missing_n))\n\n# 2) Top 25 columns by missing rate, add index label\ntop_missing_rate &lt;- miss_by_col_all |&gt;\n  slice_max(missing_rate, n = 25) |&gt;\n  arrange(desc(missing_rate)) |&gt;\n  mutate(\n    rank_label = paste0(row_number(), \". \", column),\n    rank_label = factor(rank_label, levels = rev(rank_label))  # for coord_flip\n  )\n\n# 3) Nice bar plot\np_missing &lt;- ggplot(top_missing_rate,\n                    aes(x = rank_label, y = missing_rate, fill = missing_rate)) +\n  geom_col(width = 0.8) +\n  coord_flip() +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  scale_fill_viridis_c(\n    option = \"C\",\n    direction = -1,\n    name = \"Missing rate\"\n  ) +\n  labs(\n    title = \"Top Columns by Missingness Rate\",\n    subtitle = \"Showing the 25 columns with the highest proportion of missing values\",\n    x = NULL,\n    y = \"Missingness rate\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.y  = element_text(size = 9),\n    axis.text.x  = element_text(size = 10),\n    plot.title   = element_text(face = \"bold\", size = 16),\n    plot.subtitle = element_text(size = 11),\n    legend.position = \"right\"\n  )\n\np_missing\n\n\n\n\n\n\n\n\n\nCode\n# 4) Threshold + list of columns to drop (same logic as before)\nmissing_threshold &lt;- 0.60\n\ncols_to_drop_by_missing &lt;- miss_by_col_all |&gt;\n  filter(missing_rate &gt; missing_threshold) |&gt;\n  pull(column)\n\n\nThe first plot shows the 25 columns with the highest proportion of missing values. Each bar is a column, ordered from most to least missing, and the color scale encodes the missingness rate.\nKey observations: - Several columns have almost complete missingness (≈ 95–100%), including\ntaxi_company_borough, road_ramp, bridge_highway_direction, bridge_highway_name,\nbridge_highway_segment, and taxi_pick_up_location. - Many of these fields are highly specialized (e.g., taxi or bridge/highway metadata) that apply only to a very small subset of 311 requests. - A second tier of columns (e.g., intersection_street_1, intersection_street_2, cross_street_1, cross_street_2) has moderate missingness (roughly 25–40%), typically for records where complaints do not occur at an intersection. - We decided to remove extreme missingness columns from df_clean_final, which will add noise and complexity without contributing to the main objective of the project and columns with moderate missingness but high potential value were kept for further analysis.\n\n\n2.1.2.2 2.2.2 Heatmap of Missing Data (Sampled Rows)\n\n\nCode\nset.seed(42)\nsampled_data &lt;- combined[sample(1:nrow(combined), 5000), ]\n\nmissing_long &lt;- as.data.frame(is.na(sampled_data)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"Column\", values_to = \"IsMissing\")\n\nmissing_long &lt;- cbind(RowIndex = rep(1:nrow(sampled_data), times = ncol(sampled_data)), missing_long)\n\n# Plotting heatmap of missing data\nggplot(missing_long, aes(x = Column, y = RowIndex, fill = IsMissing)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"FALSE\" = \"white\", \"TRUE\" = \"red\"), name = \"Missing\") +\n  labs(title = \"Heatmap of Missing Data (Sampled Rows)\",\n       x = \"Columns\",\n       y = \"Row Index\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nTo complement the summary bar chart, we also visualized missingness row by row for a random sample of records. In this heatmap: - Some columns form solid vertical red bands, meaning they are missing for almost all rows which correspond to the heavily missing taxi/bridge fields seen in the previous plot. - Other columns show stripe-like patterns, where only some rows are missing (e.g., closed_date for still-open complaints). - Core analytical fields such as created_date, complaint_type, and borough appear almost entirely white, confirming that they are reliable.\n\n\n\n2.1.3 2.3 Focusing on Key Categorical Variables\n\n2.1.3.1 2.3.1 Borough Distribution of 311 Complaints\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\nvalid_boros &lt;- c(\"MANHATTAN\", \"BROOKLYN\", \"QUEENS\", \"BRONX\", \"STATEN ISLAND\")\n\ndf_clean_final &lt;- combined |&gt;\n  filter(borough %in% valid_boros)\n\n# Borough counts on cleaned data\nborough_counts &lt;- df_clean_final |&gt;\n  count(borough, name = \"n\") |&gt;\n  mutate(\n    share = n / sum(n),\n    # nice index label\n    boro_label = paste0(row_number(), \". \", borough),\n    # text shown on the bar: comma count + %\n    label_text = paste0(comma(n), \" (\", percent(share, accuracy = 0.1), \")\")\n  ) |&gt;\n  arrange(desc(n)) |&gt;\n  mutate(\n    boro_label = factor(boro_label, levels = rev(boro_label))\n  )\n\nggplot(borough_counts,\n       aes(x = boro_label, y = n, fill = share)) +\n  geom_col(width = 0.7) +\n  geom_text(\n    aes(label = label_text),\n    hjust = -0.05, size = 3.5\n  ) +\n  coord_flip(clip = \"off\") +\n  scale_y_continuous(\n    labels = scales::comma,                     # &lt;-- commas\n    expand = expansion(mult = c(0, 0.30))       # extra room for labels\n  ) +\n  scale_fill_viridis_c(\n    option = \"C\",\n    direction = -1,\n    labels = scales::percent_format(accuracy = 1),\n    name = \"Share of\\ncomplaints\"\n  ) +\n  labs(\n    title = \"Borough Distribution of 311 Complaints\",\n    subtitle = \"Indexed by frequency; labels show count (comma separated) and percent of total\",\n    x = NULL,\n    y = \"Number of complaints\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.y  = element_text(size = 10),\n    axis.text.x  = element_text(size = 10),\n    plot.title   = element_text(face = \"bold\", size = 16),\n    plot.subtitle = element_text(size = 11),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\n\n\nBefore diving into more detailed modeling, we summarized the overall volume of complaints by borough. The horizontal bar chart shows both the raw counts and the percentage share for each borough, ordered by frequency:\n\nBrooklyn: 2,047,219 complaints (30.7%)\n\nQueens: 1,604,444 complaints (24.0%)\n\nManhattan: 1,408,383 complaints (21.1%)\n\nBronx: 1,365,908 complaints (20.5%)\n\nStaten Island: 249,281 complaints (3.7%)\n\nInterpretation:\n\nBrooklyn and Queens together account for more than half of all 311 complaints, which is broadly consistent with their larger populations and geographic size.\nStaten Island contributes a comparatively small share of complaints (3.7%), reflecting both its smaller population and possibly different usage patterns of 311.\n\nThis plot acts as a sanity check that the dataset reflects known patterns of NYC population and service use and also it provides context for later plots that break down complaint types and system performance within each borough.\n\n\n2.1.3.2 2.3.2 Missingness Pattern for Core Categorical Variables\n\n\nCode\n#label\ndf_clean_final &lt;- df_clean_final |&gt;\n  dplyr::select(\n    unique_key, created_date, closed_date, resolution_action_updated_date,\n    agency, agency_name, complaint_type, descriptor, status,\n    borough, city, incident_zip, incident_address,\n    latitude, longitude, location_type,\n    open_data_channel_type,\n    resolution_description\n  )\n#saveRDS(df_clean_final, \"df_clean_final.rds\")\n\n\n\n\nCode\ncombined0 &lt;- combined |&gt;\n  mutate(\n    across(where(is.character), \\(x) str_squish(x)),\n    across(where(is.character), \\(x) na_if(x, \"\"))\n  )\n\nmiss_by_col_all &lt;- combined0 |&gt;\n  summarise(across(everything(), \\(x) sum(is.na(x)))) |&gt;\n  pivot_longer(everything(), names_to = \"column\", values_to = \"missing_n\") |&gt;\n  mutate(total_n = nrow(combined0),\n         missing_rate = missing_n / total_n) |&gt;\n  arrange(desc(missing_n))\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(lubridate)\n\ndf0 &lt;- df_clean_final |&gt;\n  mutate(\n    across(where(is.character), \\(x) str_squish(x)),\n    across(where(is.character), \\(x) na_if(x, \"\")),\n    across(where(is.character), \\(x) na_if(x, \"NA\")),\n    across(where(is.character), \\(x) na_if(x, \"N/A\"))\n  )\n\n\n\n\nCode\nlibrary(redav)\ncritical_cols &lt;- c(\"location_type\", \"complaint_type\", \"borough\")\nplot_missing(df0[critical_cols])\n\n\n\n\n\n\n\n\n\nTo ensure that the main categorical variables used throughout the analysis were stable, we examined the joint missingness pattern for three key fields:\n\nborough\n\ncomplaint_type\n\nlocation_type\n\nThe pattern plot has:\n\nA bar at the top showing % rows missing for each variable.\nA matrix in the center indicating which combinations of missing/present occur.\nA bar on the right showing how common each pattern is.\n\nMain findings: - borough and complaint_type are essentially complete—almost no records are missing these fields. - location_type has a small but noticeable amount of missingness (around 10–15% of rows). The plot shows two main patterns:\n1. Complete cases (all three variables present).\n2. Cases where only location_type is missing.\n\nFor analyses that depend heavily on location_type (e.g., location-type heatmaps and action distributions), we restrict to complete cases so that percentages are meaningful.\nFor other analyses, we kept \"Unknown\" or NA category for location_type, so that rows are not discarded unnecessarily.\n\n\n\n\n2.1.4 2.4 Spatial Data Quality Checks\nMany of the most interesting 311 questions are spatial (Which neighborhoods complain the most? Where are issues slowest to resolve?), so we checked the quality of the geographic fields before using them.\n\n2.1.4.1 2.4.1 Latitude–Longitude Validity\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n# 1. Compute geolocation validity\ngeo_check &lt;- df0 |&gt;\n  transmute(\n    latitude = suppressWarnings(as.numeric(latitude)),\n    longitude = suppressWarnings(as.numeric(longitude)),\n    geo_ok = !is.na(latitude) & !is.na(longitude) &\n      between(latitude, 40, 41.2) &\n      between(longitude, -74.5, -73.2)\n  )\n\n# 2. Prepare summary for % view\ngeo_summary &lt;- geo_check |&gt;\n  count(geo_ok) |&gt;\n  mutate(\n    label = ifelse(geo_ok, \"Valid NYC Coordinates\", \"Invalid / Missing Coordinates\"),\n    pct = n / sum(n)\n  )\n\n# 3. Plot\nggplot(geo_summary, aes(x = label, y = pct, fill = label)) +\n  geom_col(width = 0.6, alpha = 0.85) +\n  geom_text(aes(label = percent(pct, accuracy = 0.1)),\n            vjust = -0.5, size = 5) +\n  scale_y_continuous(labels = percent_format(accuracy = 1),\n                     expand = expansion(mult = c(0, 0.1))) +\n  scale_fill_manual(values = c(\"#1b9e77\", \"#d95f02\")) +\n  labs(\n    title = \"Geolocation Validity of 311 Records\",\n    subtitle = \"Latitude–longitude checked against the NYC bounding box\",\n    x = NULL,\n    y = \"% of Records\",\n    fill = NULL\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nIn the above plot we classified each record as:\n\nhaving valid NYC coordinates, or\n\nhaving invalid or missing coordinates (outside the region or NA).\n\nThe bar chart shows: - 98.5% of records have valid latitude–longitude pairs.Only 1.5% are invalid or missing.\n- When making maps or location summaries, we’ll only use the valid coordinate subset. This prevented us from plotting points that are clearly wrong (like locations outside of NYC or at (0, 0)).\n\n\n2.1.4.2 2.4.2 ZIP Code Quality\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ndf_zip &lt;- df_clean_final |&gt;\n  mutate(\n    zip_num = suppressWarnings(as.numeric(incident_zip)),\n    zip_category = case_when(\n      is.na(zip_num) ~ \"Missing ZIP\",\n      zip_num &gt;= 10000 & zip_num &lt;= 11697 ~ \"Valid NYC ZIP\",\n      TRUE ~ \"Invalid ZIP\"\n    )\n  ) |&gt;\n  count(zip_category) |&gt;\n  mutate(\n    percent = n / sum(n),\n    label = paste0(comma(n), \" (\", percent_format(accuracy = 0.1)(percent), \")\")\n  )\n\nggplot(df_zip, aes(x = reorder(zip_category, -n), y = n, fill = zip_category)) +\n  geom_col(width = 0.6) +\n  \n  # FIX: always place labels *just above* bars safely\n  geom_text(\n    aes(label = label),\n    vjust = -0.8,   # pull upward slightly\n    size = 5,\n    fontface = \"bold\"\n  ) +\n  \n  scale_fill_manual(values = c(\n    \"Valid NYC ZIP\" = \"#1b9e77\",\n    \"Invalid ZIP\"   = \"#d95f02\",\n    \"Missing ZIP\"   = \"#7570b3\"\n  )) +\n  \n  # FIX: expand limits so labels never get clipped or flipped\n  scale_y_continuous(\n    labels = comma,\n    expand = expansion(mult = c(0, 0.15))  # extra 15% space above\n  ) +\n  \n  labs(\n    title = \"ZIP Code Quality Summary\",\n    subtitle = \"Distribution of valid, invalid, and missing ZIP codes\",\n    x = NULL,\n    y = \"Number of Records\"\n  ) +\n  \n  theme_minimal(base_size = 15) +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 18),\n    plot.subtitle = element_text(size = 13)\n  )\n\n\n\n\n\n\n\n\n\nCode\ndf_clean &lt;- df_clean_final %&gt;%\n  mutate(\n    zip_num = suppressWarnings(as.numeric(incident_zip))\n  ) %&gt;%\n  filter(\n    !is.na(zip_num),\n    zip_num &gt;= 10000,\n    zip_num &lt;= 11697\n  ) %&gt;%\n  select(-zip_num)\n\n\nI performed a similar quality check for ZIP codes by comparing each incident_zip to a list of valid NYC ZIP codes and allowing for missing values. The bar chart summarizes counts and percentages:\n\n6,610,015 records (99.0%) have a valid NYC ZIP code.\n\n65,132 records (1.0%) have missing ZIP codes.\n\nOnly 88 records (0.0%) have clearly invalid ZIP codes.\n\nCleaning decision.\n\nRecords with invalid ZIPs were treated as data errors and effectively ignored in ZIP-level summaries.\nRecords with missing ZIPs were kept in the main dataset but excluded from analyses that group by ZIP code.\n\nOverall, both latitude–longitude and ZIP quality checks suggest that spatial information in the dataset is highly reliable, with only a small fraction of problematic records.\n\n\n\nCode\nsaveRDS(df_clean_final, \"df_clean_final.rds\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1. Opening Remarks and Motivation</span>"
    ]
  }
]